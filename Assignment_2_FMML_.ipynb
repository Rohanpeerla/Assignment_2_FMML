{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZvROOR2GDhZ7qG8yZtfts",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohanpeerla/Assignment_2_FMML/blob/master/Assignment_2_FMML_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name:Rohan Peerla\n",
        "\n",
        "Roll no:20230067"
      ],
      "metadata": {
        "id": "YFdvhAzTUIVM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_2OfzBfRPqD"
      },
      "outputs": [],
      "source": [
        "#question 1 Does averaging the validation accuracy across multiple splits give more consistent results?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Averaging multiple validation accuracy across multiple splits generally gives more consistent rules.\n",
        "\n",
        "Yes, averaging the validation accuracy across multiple splits generally gives more consistent results. This is because cross-validation helps to reduce the variance of the model's performance estimate."
      ],
      "metadata": {
        "id": "YaIHxn0-RVlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#question 2 Does it give more accurate estimate of test accuracy?"
      ],
      "metadata": {
        "id": "3QHmG1muRylP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes averaging the validation accuracy across multiple splits generally gives a more accurate `\n",
        "\n",
        "Yes, averaging the validation accuracy across multiple splits generally gives a more accurate estimate of test accuracy. This is because cross-validation helps to reduce the variance of the model's performance estimate.\n",
        "\n",
        "When we train a model on a training set, there is always some risk of overfitting. Overfitting occurs when the model learns the training data too well, and is unable to generalize to new data.\n",
        "\n",
        "Cross-validation helps to reduce the risk of overfitting by splitting the training data into multiple folds, and then training and evaluating the model on each fold. The validation accuracy is then calculated as the average of the model's performance on each fold.\n",
        "\n",
        "If the model is overfitting to the training data, then the validation accuracy will be lower than the training accuracy. This is because the model is not able to generalize to the new data in the validation folds.\n",
        "\n",
        "By averaging the validation accuracy across multiple splits, we can get a more accurate estimate of the model's true performance on new data. This is because the average validation accuracy takes into account the model's performance on a variety of different training and validation folds."
      ],
      "metadata": {
        "id": "LyUNFfewR52I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#question 3 What is the effect of the number of iterations on the estimate? Do we get a better estimate with higher iterations?"
      ],
      "metadata": {
        "id": "VaOeXOeeS5Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "effect of the number of iterations on the cross-validation estimate is complex, and it depends on a number of factors, including:\n",
        "\n",
        "The complexity of the model: More complex models tend to require more iterations to converge.\n",
        "The size of the dataset: Larger datasets tend to require more iterations to train.\n",
        "The amount of noise in the data: Data with more noise tends to require more iterations to train.\n",
        "The specific cross-validation method used: Some cross-validation methods, such as repeated k-fold cross-validation, require more iterations than others.\n",
        "\n",
        "In general, using more iterations will tend to produce a more accurate estimate of the model's performance on new data. However, there are also some potential drawbacks to using too many iterations. For example, using too many iterations can increase the computational cost of training the model, and it can also increase the risk of overfitting.\n",
        "\n",
        "A good rule of thumb is to use enough iterations so that the model's performance on the validation set has stabilized. Once the model's performance on the validation set has stabilized, increasing the number of iterations is unlikely to improve the accuracy of the cross-validation estimate."
      ],
      "metadata": {
        "id": "a0AGgesTS-6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#question 4 Consider the results you got for the previous questions. Can we deal with a very small train dataset or validation dataset by increasing the iterations?Consider the results you got for the previous questions. Can we deal with a very small train dataset or validation dataset by increasing the iterations?"
      ],
      "metadata": {
        "id": "tQQfikVsTV-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes we can deal with a very small train dataset or validation dataset by increasing the iterations. However, there are some important things to keep in mind:\n",
        "\n",
        "Increasing the iterations can increase the computational cost of training the model.\n",
        "\n",
        "Increasing the iterations can also increase the risk of overfitting.\n",
        "\n",
        "To avoid overfitting, it is important to use a variety of techniques, such as regularization and early stopping. It is also important to use a validation set that is representative of the data that the model will be used on in production.\n",
        "\n",
        "Here are some additional tips for dealing with a very small train dataset or validation dataset:\n",
        "\n",
        "Use a simpler model. More complex models tend to require more data to train.\n",
        "Use data augmentation techniques to increase the size of your dataset.\n",
        "Use transfer learning to start with a pre-trained model that has been trained on a large dataset.\n",
        "Use a validation method that is suitable for small datasets, such as leave-one-out cross-validation."
      ],
      "metadata": {
        "id": "DEeZRBEVTk3E"
      }
    }
  ]
}